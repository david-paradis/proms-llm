# Assistant d'Interprétation de PROMs via LLM

Une preuve de concept démontrant l'utilisation d'un modèle de langage (LLM) pour interpréter et résumer les résultats de questionnaires PROMs (Patient-Reported Outcome Measures).

## Installation

1. Cloner le dépôt

```bash
git clone https://github.com/votre-nom/assistant-proms-llm.git
cd assistant-proms-llm
```

2. Créer un environnement virtuel et installer les dépendances

```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. Configurer les clés API

Créez un fichier `.env` à la racine du projet avec vos clés API: 